[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Datasets",
    "section": "",
    "text": "All data used in the analysis is publicly available at the links provided below.\n\nGround truth data | 2 datasets, 5 damaged samples (*)\n\n\n\n\nDataset\nTreatment\nSorting\nSample\nAccession\nDownload\n\n\n\n\n\n\n\n\n\n\n\n\n\n*\nHEK293 cell line\nStaurosporine (1 μM, 2 hours)\nAnnexin V+ and DAPI+\nApoptotic\nPRJEB33078\nENA, BAM files\n\n\n*\nHEK293 cell line\nStaurosporine (1 μM, 2 hours)\nAnnexin V+ and DAPI-\nPro-apoptotic\nPRJEB33078\nENA, BAM files\n\n\n\nHEK293 cell line\n-\nAnnexin V- and DAPI-\nControl\nPRJEB33078\nENA, BAM files\n\n\n\n\n\n\n\n\n\n\n\n*\nGM18507 cell line\nTNF-alpha (100 ng/ml, 24 hours)\nPropidium iodide+ and Annexin V+\nDead\nEGAS00001003753\nZenodo, TENX049_SA928_003_sceset_v3_raw.rds\n\n\n*\nGM18507 cell line\nTNF-alpha (100 ng/ml, 24 hours)\nPropidium iodide- and Annexin V+\nDying\nEGAS00001003753\nZenodo, TENX049_SA928_002_sceset_v3_raw.rds\n\n\n\nGM18507 cell line\n-\nPropidium iodide- and Annexin V-\nControl\nEGAS00001003753\nZenodo, TENX049_SA928_001_sceset_v3_raw.rds\n\n\n\n\n\n\n\n\n\n\n\n*\nPDX\nTNF-alpha (100 ng/ml, 24 hours)\nPropidium iodide+ and Annexin V+\nDead\nEGAS00001003753\nZenodo, TENX019_SA604X7XB02089_004_sceset_v3_raw.rds\n\n\n\nPDX\n-\nPropidium iodide- and Annexin V-\nControl\nEGAS00001003753\nZenodo, TENX019_SA604X7XB02089_002_sceset_v3_raw.rds\n\n\n\n\n\nNon-ground truth data | 15 datasets, 15 samples\n\n\n\nDataset\nTissue Type\nAccession\nDownload\nData type\nProtocol\n\n\n\n\nHealthy Human tissue extracts\n\n\n\n\n\n\n\n4K PBMC (10x Genomics 2017)\nPBMC\nGSE108444\nLink\nFASTQ\n10x v2, normal\n\n\nHealthy Human Lung (Habermann, 2020)\nLung\nGSE135893\nLink1, Link2\nFASTQ\n10x v2, extra length\n\n\nLiver atlas (MacParland, 2018)\nLiver\nGSE115469\nLink\nBAM to FASTQ\n10x v2, normal\n\n\n\n\n\n\n\n\n\n\nDiseased Human tissue extracts\n\n\n\n\n\n\n\nTB PBMC (Cai, 2020)\nPBMC\nPRJNA605083\nLink1, Link2\nFASTQ\n10x v2, normal\n\n\nTB Lung (Wang, 2023)\nLung\nGSE192483\nLink1, Link2\nFASTQ\n10x v2, extra length\n\n\nHBV Liver (Beudeker, 2024)\nLiver\nGSE247322\nLink\nSRA to FASTQ\n10x v3\n\n\n\n\n\n\n\n\n\n\nMouse tissue extracts\n\n\n\n\n\n\n\n10K Mouse PBMC (10X Genomics, 2021)\nPBMC\n10X Genomics\nLink\nFASTQ\n10x v3\n\n\nMouse lung (Li, 2021)\nLung\n10X Genomics\nLink1, Link2\nFASTQ\n10x v3\n\n\nLiver necroposis (Vucur, 2023)\nLiver\nGSE166875\nLink1, Link2\nFASTQ\n10x v2, normal\n\n\n\n\n\n\n\n\n\n\nHuman tumours\n\n\n\n\n\n\n\nHuman Hodgkin’s Lymphoma (10x Genomics 2020b)\nLymphoid tissue\n10X Genomics\nLink\nFASTQ\n10x v3\n\n\nHuman Glioblastoma (10x Genomics 2020)\nGlioblastoma\n10X Genomics\nLink\nFASTQ\n10x v3\n\n\nHuman Ductal Carcinoma (10x Genomics 2021)\nBreast cancer tissue\n10X Genomics\nLink\nFASTQ\n10x v3\n\n\n\n\n\n\n\n\n\n\nHuman cell lines\n\n\n\n\n\n\n\n5k A549, Lung Carcinoma Cells (10X Genomics 2021)\n-\nGSE161363\nLink\nFASTQ\n10x v3\n\n\nRaji and Jurkat Cells (10X Genomics, 2021)\n-\n10X Genomics\nLink\nFASTQ\n10x v3\n\n\nHCT-116 (Meir, 2016)\n-\nGSE144357\nLink1, Link2\nFASTQ\n10x v2, normal\n\n\n\n\n\nSimulated data\n1 parent dataset, 30 final samples\nAll simulated samples were created from a dataset available in R through the SeuratData package. The interferon-treated PBMC dataset was selected as it contains case and control data already intergrated into a single object with cell annotations.\n# IFNB-Stimulated & Control PBMC data\nlibrary(SeuratData)\nInstallData(\"ifnb\")\ndata(\"ifnb\")\nifnb &lt;- UpdateSeuratObject(ifnb)\nThese foundational simulated samples were altered by randomly extracting a fixed percentage of their cells (2.5, 5, 10, 15, or 20), passing them through a damage-pertubration function, and reintroducing them to the sample. The resulting datasets are available for download on Zenodo, ."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "Filtering cells that have lost transcriptomic information during isolation protocols, referred to here as “damaged cells”, is a fundamental quality control task for single cell RNA sequencing (scRNA-seq) data analysis. However, unlike other aspects of cell quality control, such as doublet and empty droplet removal, how to best filter damaged cells from single cell data has not been thoroughly explored.\nSearching online tutorials, forums, and published articles will bring you to the same conclusion: filter cells that express a high proportion of mitochondrial genes. This is because damaged cells are understood to have impaired membranes where cytoplasmic RNA content has escaped. It is for the same reason that the number of unique transcripts and UMIs per cell are also recommended metrics for identifying damaged cells.\nMore recently, the proportion of unspliced RNA, targeting transcripts that remain intact in the nucleus in the event of damage, and ribosomal RNA, targeting those that do not, are offered as damaged cell quality control metrics. Extending from this, the expression of the nuclear-located long non-coding RNA, MALAT1, has also been suggested as a potential metric for identifying damaged cells.\nThe problem for a user then arises in two forms: 1. Which cell quality controls metrics should I use and 2. According to what outlier detection framework should I perform filtering\nDamaged cell detection tools provide their own solutions to the problems. However, the relative effectiveness of these tools, and of manual methods, is yet to be systematically determined. Our goal with this benchmark is to provide an objective answer to the question of how to best filter damaged cells in single cell data. Providing users with information on the characteristics of each available strategy, we aim for comprehensive, robust action towards addressing this quality control task."
  },
  {
    "objectID": "index.html#benchmark-motivation",
    "href": "index.html#benchmark-motivation",
    "title": "Overview",
    "section": "",
    "text": "Filtering cells that have lost transcriptomic information during isolation protocols, referred to here as “damaged cells”, is a fundamental quality control task for single cell RNA sequencing (scRNA-seq) data analysis. However, unlike other aspects of cell quality control, such as doublet and empty droplet removal, how to best filter damaged cells from single cell data has not been thoroughly explored.\nSearching online tutorials, forums, and published articles will bring you to the same conclusion: filter cells that express a high proportion of mitochondrial genes. This is because damaged cells are understood to have impaired membranes where cytoplasmic RNA content has escaped. It is for the same reason that the number of unique transcripts and UMIs per cell are also recommended metrics for identifying damaged cells.\nMore recently, the proportion of unspliced RNA, targeting transcripts that remain intact in the nucleus in the event of damage, and ribosomal RNA, targeting those that do not, are offered as damaged cell quality control metrics. Extending from this, the expression of the nuclear-located long non-coding RNA, MALAT1, has also been suggested as a potential metric for identifying damaged cells.\nThe problem for a user then arises in two forms: 1. Which cell quality controls metrics should I use and 2. According to what outlier detection framework should I perform filtering\nDamaged cell detection tools provide their own solutions to the problems. However, the relative effectiveness of these tools, and of manual methods, is yet to be systematically determined. Our goal with this benchmark is to provide an objective answer to the question of how to best filter damaged cells in single cell data. Providing users with information on the characteristics of each available strategy, we aim for comprehensive, robust action towards addressing this quality control task."
  },
  {
    "objectID": "index.html#structure-of-benchmark",
    "href": "index.html#structure-of-benchmark",
    "title": "Overview",
    "section": "Structure of benchmark",
    "text": "Structure of benchmark"
  },
  {
    "objectID": "index.html#webpage-tour",
    "href": "index.html#webpage-tour",
    "title": "Overview",
    "section": "Webpage tour",
    "text": "Webpage tour\nThis\nBut searching for true damaged droplets in a sample-specific manner is tedious and not always intuitive, leading to user-defined filtering that lacks reproducibility.\nThe analysis is made up of four components beginning with a search for manual and tool-based strategies for damaged cell filtering, A. To test the strategies, data was collected and processed, B, for testing and comparison, C. An overview of the results are condensed, D, into sections for the user, containing usage recommendations, and the developers, containing areas for improvement. \n\n\n\nAlt text"
  },
  {
    "objectID": "contribute.html",
    "href": "contribute.html",
    "title": "Contribute",
    "section": "",
    "text": "The results of our benchmark (Damage Bench, link) offer a static view of the current landscape of damaged cell detection. As new strategies emerge, and new ground truth datasets become available, we intend for them to be added to our benchmarking framework.\nIf you can offer a novel strategy, metric to benchmarking the strategies, or dataset, please think of contributing."
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "Results",
    "section": "",
    "text": "Explore the current consensus results below. The order of the strategies can be changed by clicking the arrows positioned by the column header of a metric, such as performance.\nFor less cluttered viewing, select the columns you wish to see using the Column visibility button."
  },
  {
    "objectID": "results.html#damaged-cell-detection-strategies",
    "href": "results.html#damaged-cell-detection-strategies",
    "title": "Results",
    "section": "Damaged Cell Detection Strategies",
    "text": "Damaged Cell Detection Strategies"
  },
  {
    "objectID": "benchmark.html",
    "href": "benchmark.html",
    "title": "Benchmark",
    "section": "",
    "text": "Article: https://doi.org/10.1186/s13059-022-02820-w\n  \nIdentifies damaged cells within sample-specific clusters using the Louvain algorithm for clustering and MAD-based univariate outlier detection of UMI, feature counts, and mitochondrial or ribosomal percentages.\nTutorial\n\n\n\nArticle: https://doi.org/10.1186/s13059-021-02547-0\n  \nUses nuclear fraction (ratio of unspliced to spliced transcripts) and UMI counts with an Expectation-Maximization model to classify damaged cells.\nTutorial\n\n\n\nArticle: https://doi.org/10.1007/978-3-030-26969-2_47\n  \nCombines multiple quality control measures to detect damaged cells, focusing on ensemble-based metrics\n\n\n\nArticle: https://doi.org/10.1371/journal.pcbi.1009290\n  \nApplies a mixture model to mitochondrial percentage and library complexity to assign posterior probabilities for identifying damaged cells.\nTutorial\n\n\n\nArticle: https://doi.org/10.1186/s13059-023-02859-3\n  \nAutomates sample-wide multivariate outlier detection using robust Mahalanobis distances for mitochondrial, ribosomal, and UMI counts.\nTutorial\n\n\n\nArticle: https://doi.org/10.1093/bioinformatics/btw777\n  \nProvides diagnostic visualizations and filtering functions to assess and remove damaged cells using user-defined thresholds\nTutorial\n\n\n\nArticle: https://doi.org/10.1101/2023.02.07.526574\n\n \nDetects apoptotic cells using scaled and transformed QC features with logistic regression and cross-validation for soft labeling.\n\n\n\n\n\n\n\n\n\nInvolves setting a fixed value for mitochondrial percent expression above which cells are classified as damaged. Implementation of this method varies based on preferred platform, for example using default functions in the Seurat R package,\n\ndata[[\"percent.mt\"]] &lt;- PercentageFeatureSet(data, pattern = \"^MT-\")\ndata &lt;- subset(data, subset = percent.mt &lt; 10)\n\nAnd the Scanpy python package,\n\ndata.var['mt'] = data.var_names.str.startswith('MT-')\nsc.pp.calculate_qc_metrics(data, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\ndata = data[data.obs.pct_counts_mt &lt; 10, :]\n\n\n\n\n\n\nThresholds set based on the dataset’s distribution of a certain metric using a simple percentile-based method. Upper thresholds (e.g., for mitochondrial and MALAT1 percent expression) were set at the 90th percentile, while lower thresholds (e.g., for ribosomal percent expression and library size) were set at the 10th percentile. Note: library size refers to an equally weighted consideration of the log10 transformed UMI and feature counts.\n\n\nFiltering cells with\n\nmitochondrial percent expression above the 90th percentile.\n\n\n\n\nFiltering cells with\n\nmitochondrial percent expression above the 90th percentile AND\nwith ribosomal percent expression below the 10th percentile.\n\n\n\n\nFiltering cells with\n\nmitochondrial percent expression above the 90th percentile,\nribosomal percent expression below the 10th percentile AND\nlibrary size below the 10th percentile.\n\n\n\n\nFiltering cells with\n\nlibrary sizes below the 10th percentile.\n\n\n\n\nFiltering cells with\n\nMALAT1 percent expression above the 90th percentile.\n\n\n\n\nFiltering cells with\n\nMALAT1 percent expression above the 90th percentile AND\nmitochondrial percent expression above the 90th percentile."
  },
  {
    "objectID": "benchmark.html#strategies",
    "href": "benchmark.html#strategies",
    "title": "Benchmark",
    "section": "",
    "text": "Article: https://doi.org/10.1186/s13059-022-02820-w\n  \nIdentifies damaged cells within sample-specific clusters using the Louvain algorithm for clustering and MAD-based univariate outlier detection of UMI, feature counts, and mitochondrial or ribosomal percentages.\nTutorial\n\n\n\nArticle: https://doi.org/10.1186/s13059-021-02547-0\n  \nUses nuclear fraction (ratio of unspliced to spliced transcripts) and UMI counts with an Expectation-Maximization model to classify damaged cells.\nTutorial\n\n\n\nArticle: https://doi.org/10.1007/978-3-030-26969-2_47\n  \nCombines multiple quality control measures to detect damaged cells, focusing on ensemble-based metrics\n\n\n\nArticle: https://doi.org/10.1371/journal.pcbi.1009290\n  \nApplies a mixture model to mitochondrial percentage and library complexity to assign posterior probabilities for identifying damaged cells.\nTutorial\n\n\n\nArticle: https://doi.org/10.1186/s13059-023-02859-3\n  \nAutomates sample-wide multivariate outlier detection using robust Mahalanobis distances for mitochondrial, ribosomal, and UMI counts.\nTutorial\n\n\n\nArticle: https://doi.org/10.1093/bioinformatics/btw777\n  \nProvides diagnostic visualizations and filtering functions to assess and remove damaged cells using user-defined thresholds\nTutorial\n\n\n\nArticle: https://doi.org/10.1101/2023.02.07.526574\n\n \nDetects apoptotic cells using scaled and transformed QC features with logistic regression and cross-validation for soft labeling.\n\n\n\n\n\n\n\n\n\nInvolves setting a fixed value for mitochondrial percent expression above which cells are classified as damaged. Implementation of this method varies based on preferred platform, for example using default functions in the Seurat R package,\n\ndata[[\"percent.mt\"]] &lt;- PercentageFeatureSet(data, pattern = \"^MT-\")\ndata &lt;- subset(data, subset = percent.mt &lt; 10)\n\nAnd the Scanpy python package,\n\ndata.var['mt'] = data.var_names.str.startswith('MT-')\nsc.pp.calculate_qc_metrics(data, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\ndata = data[data.obs.pct_counts_mt &lt; 10, :]\n\n\n\n\n\n\nThresholds set based on the dataset’s distribution of a certain metric using a simple percentile-based method. Upper thresholds (e.g., for mitochondrial and MALAT1 percent expression) were set at the 90th percentile, while lower thresholds (e.g., for ribosomal percent expression and library size) were set at the 10th percentile. Note: library size refers to an equally weighted consideration of the log10 transformed UMI and feature counts.\n\n\nFiltering cells with\n\nmitochondrial percent expression above the 90th percentile.\n\n\n\n\nFiltering cells with\n\nmitochondrial percent expression above the 90th percentile AND\nwith ribosomal percent expression below the 10th percentile.\n\n\n\n\nFiltering cells with\n\nmitochondrial percent expression above the 90th percentile,\nribosomal percent expression below the 10th percentile AND\nlibrary size below the 10th percentile.\n\n\n\n\nFiltering cells with\n\nlibrary sizes below the 10th percentile.\n\n\n\n\nFiltering cells with\n\nMALAT1 percent expression above the 90th percentile.\n\n\n\n\nFiltering cells with\n\nMALAT1 percent expression above the 90th percentile AND\nmitochondrial percent expression above the 90th percentile."
  },
  {
    "objectID": "benchmark.html#metrics",
    "href": "benchmark.html#metrics",
    "title": "Benchmark",
    "section": "Metrics",
    "text": "Metrics\n\nPerformance metrics\n\\[\n\\text{Performance} = \\text{Precision} + \\text{PR-AUC} + \\text{Jaccard Index} + \\text{F1 Score}\n\\]\nwhere,\n\nPrecision ( 0, 1 ) : Of all damaged predictions made, what proportion were true damaged cells?\nMedian score taken from the 5 experimentally verified ground truth datasets.\nPR-AUC ( 0, 1 ) : Of all predictions, were damaged cells correctly and comprehensively identified (i.e., were true damaged cells missed)?\nMedian score taken from the 5 experimentally verified ground truth datasets.\nJaccard Index ( 0, 1 ) : How similar were the filtered datasets to the positive, damage-free control (closer to the control indicates better correction for damage)?\nMedian score taken from the 30 simulated ground truth datasets.\nF1 Score ( 0, 1 ) : Were the differentially expressed genes of the filtered datasets correct compared to the positive, damage-free control?\nMedian score taken from the 30 simulated ground truth datasets.\n\nThus, Performance lies in the range ( 0, 4 ) , with 4 being the highest performance possible.\nYou can view the individual performance scores for the strategies, here.\n\n\n\nPerformance agnostic metrics\n\nDamage focus\nThis score measures how many of the damaged predictions originate from the population of damaged cells that have a significantly altered transcriptomic profile compared to control cells. Here, a strategy that is highly specific to this population, rather than to the population of damaged cells that appear identical to control cells and pose no contamination risk, is ideal. This value, derived from the median across the 5 experimentally verified ground truth datasets, is a proportion and lies in the range ( 0, 1 ) where we pose that closer to 1 is ideal.\n\n\n\nStringency\nThis score measures how many of the cells present were labelled as damaged by the strategy. While this proportion is not especially valuable when viewed in an isolated dataset, collecting it across many datasets, here 51, gives a good idea of how stringent the strategy is in general and how a user can expect it to be when applied to new data. This is offered in response to one of the most prominent concerns for damaged cell filtering strategies: that they will remove too many cells (too stringent), or won’t remove enough (too lenient). Being a proportion, this score ranges from ( 0, 1 ) where closer to 1 represents more stringent strategies.\n\n\n\nConsistency\nThis score measures the deviation in the output of a tool across datasets. This is made up of two components: the deviation in the proportion of damaged cells detected by a strategy and the deviation in the similarity of the strategy output compared to that of other strategies. In other words, the consistency of a strategy, (i), is calculated as,\n\\[\n\\text{Consistency}_\\text{ i} = 1 - \\left( 0.5 \\cdot \\text{damage deviation}_\\text{ i} + 0.5 \\cdot \\text{similarity deviation}_\\text{ i } \\right)\n\\]\nthat lies in the range ( 0, 1 ).\n\nMore specifically,\n\\[\n\\text{damage deviation}_\\text{ i} = \\sigma\\ \\text{( stringency}_\\text{ i })\n\\] taken across datasets and stringency refers to the proportion of cells marked as damaged by the strategy. To transform this value within [0, 1], we performed min-max scaling across all tools, j,\n\\[\n\\text{damage deviation}_\\text{ i} = \\frac{\n    \\text{damage deviation}_\\text{ i} - \\min\\left( \\text{damage deviation}_\\text{ j} \\right)\n}{\n    \\max\\left( \\text{damage deviation}_\\text{ j} \\right) - \\min\\left( \\text{damage deviation}_\\text{ j} \\right)\n}\n\\]\nNote that this was calculated for each dataset type = ground truth, non-ground truth, and simulated = to find a median damage deviation score for each strategy. This was done due to address the imbalance between dataset types.\nSimilarily, \\[\n\\text{similarity deviation}_\\text{ i} = \\text{median (} {\\sigma_j(\\kappa_{ij})} )\n\\] for a strategy, i, compared to each other strategy, j, and the median is found across strategies. Note that scaling was performed,\n\\[\n\\text{similarity deviation}_\\text{ i} = \\frac{\n    \\text{similarity deviation}_\\text{ i} - \\min\\left( \\text{similarity deviation}_\\text{ j} \\right)\n}{\n    \\max\\left( \\text{similarity deviation}_\\text{ j} \\right) - \\min\\left( \\text{similarity deviation}_\\text{ j} \\right)\n}\n\\] and the final similarity score found by taking the median across the three dataset types.\n\n\n\nUsability\n\n\nTo add a new metric or suggest an adjustment to the above metrics, please visit the Contribute page."
  }
]